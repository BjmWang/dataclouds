---
title: 不平衡数据处理
date: 2016-06-16 19:34:12
tags:
---


传统统计方法往往是抽样统计，样本一般是经过精心挑选，这样的样本往往满足一定的条件。但是在大数据下，更倾向于全量数据分析，而非抽样统计，全量数据带来的问题除了数据量大导致的问题之外还有另外一些问题，例如数据错误率高，数据不平衡等，今天要讲到的就是在全量数据下，对于不平衡数据的处理。

在处理不平衡数据前，首先要明确，何谓不平衡数据（imbalanced dataset），不平衡数据分为两种：

* 类间的不均衡：不同类别之间样本数量差距太大，例如类别A占了总样本99.9%，其他类别只占据了0.1%。
* 类内不均衡：少数类样本集中也许还包含一个少数有限样本的子集。

为什么对不平衡数据的研究是相当重要的，举个简单的例子，假设我们有一批数据，里面包含一个人的身体信息以及是否患有癌症，根据数据能够发现99%的人都没有癌症，1％的人患有癌症，现在需要依据这一批数据来预测一个人是否患有癌症，可以通过投机取巧发现一点： ` 不用做任何预测，直接判断这个人未患有癌症 `  其准确率就可以达到99%，而通过机器学习等方法训练出的模型来预测，效果反而还不如直接判断的准确率高。这样的情况，不是我们所希望看到的，造成这样的问题，其根本原因在于数据类别之间的比率差距太大，这就是不平衡数据带来的一系列问题。在大多数情况下，我们面临的都是不平衡数据，包括但不限于如下领域：

*  医疗诊断
*  文本分类
*  检测石油泄漏的雷达图像
*  信息检索

因此相比对数据分析，如何对不平衡数据进行处理，似乎已经成了一项必须要做的事情，当不同类别数据比例达到100:1，1000:1，10000:1，并且在每一个案例中，一个类严重代表另一个类别，那么就必须要进行平衡处理。针对不平衡数据的处理方法目前有很多种，但是归纳下来几乎都可以总结为如下两种：

* 对数据本身做处理：既然数据是不平衡的，那么就对数据进行重采样，将小分类数据按照一定策略进行重采样，将其增大，但是存在 ` 过拟合 ` 的的风险，另一种是抽样将大分类抽取数据，使其和小分类差不多，但是存在 ` 欠拟合 `的风险。

* 对使用的算法进行处理：从算法的角度出发，考虑不同误分类情况代价的差异性对算法进行优化，对错误的数据进行加权再处理。

##### 基于数据的处理方式

1. 随机采样
顾名思义，随机采样就是将样本随机的抽取一些数据，再和原来的数据组成新的数据，随机采样分为两种：
* 随机过采样：从多数类别数据$S_maj$中，随机抽取大小和少数类别差不多的数据$E$，再和少数类别组合成新的训练集：$S_min+E$
* 随机欠采样：从少的数组集$S_min$中，随机抽取部分数据$E$，再和原来数据混合，不停重复此步骤，直到最终少数类别数据和多数类别数据大小差不多，产生新的数据集$S_maj+E$。抽取数据的方式也分为两种：` 有放回 ` 和 ` 无放回 `

2. smote
随机采样是对不平衡数据最直接简单粗暴的做法，不可避免的会造成过拟合或者欠拟合的情况，目前来说还没有一种通用的解决方案，能够同时处理过拟合的问题又可以解决欠拟合的问题，所以每一种情况都被独立开来，例如smote通过修改随机欠采样方法，对少数类样本进行分析并根据少数类样本人工合成新样本添加到数据集中，有效的处理了数据过拟合的问题。smote算法的思想是合成新的少数类样本，合成的策略是对每个少数类样本a，从它的最近邻中随机选一个样本b，然后在a、b之间的连线上随机选一点作为新合成的少数类样本，过程如下：

* 对于少数类中每一个样本$x$，以欧氏距离为标准计算它到少数类样本集$S_min$中所有样本的距离，得到其k近邻。
*  根据样本不平衡比例设置一个采样比例以确定采样倍率$N$，对于每一个少数类样本$x$，从其k近邻中随机选择若干个样本，假设选择的近邻为$\hat{x}$。
*  对于每一个随机选出的近邻$\hat{x}$，分别与原样本按照如下的公式构建新的样本。 ![](http://upload-images.jianshu.io/upload_images/50828-6db9a3815b9fa203.png?imageMogr2/auto-orient/strip%7CimageView2/2)

 论文提供了伪代码实现：![](http://img.blog.csdn.net/20150922095710042)


3. Random forests
smote解决的是过拟合的问题，还存在一种情况是欠拟合，类似于 ` 随机森林 ` 这样的算法，就是用来解决欠拟合的情况，随机森林构建于决策树之上，顾名思义，就是随机的构建一个包含多个决策树的森林。随机森林里的决策树之间是独立的，在随机森林模型构建好以后，对于新来的测试样本数据，随机森林模型会让其中的每个决策树分别做一次预测，然后统计出现此处最多的预测标签，并将它作为最终的预测标签。随机森林算法运用的就是集成学习的思想，在实践中，随机森林往往都有很好表现，并且多次预测结果稳定并且精度非常高，决策树在生成的过程当中分别在行方向和列方向上添加随机过程，行方向上构建决策树时采用放回抽样（bootstraping）得到训练数据，列方向上采用无放回随机抽样得到特征子集，并据此得到其最优切分点，这便是随机森林算法的基本原理。下图给出了随机森林算法分类原理，从图中可以看到，随机森林是一个组合模型，内部仍然是基于决策树，同单一的决策树分类不同的是，随机森林通过多个决策树投票结果进行分类，算法不容易出现过度拟合问题。![](http://www.ibm.com/developerworks/cn/opensource/os-cn-spark-random-forest/img003.png)

4. easy ensemble
easy ensemble每次从多数类中抽样出和少数类数目差不多的样本，然后和少数类样本组合作为训练集。在这个训练集上学习一个adaboost分类器。 最后预测的时候，是使用之前学习到的所有adaboost中的弱分类器（就是每颗决策树）的预测结果向量（每个树给的结果组成一个向量）和对应的权重向量做内积，然后减去阈值，根据差的符号确定样本的类别。easy ensemble 算法被认为是非监督学习算法，因此它每次都独立利用可放回随机抽样机制来提取多数类样本

5. balance cascade
balance cascade算法是一种级联算法，BalanceCascade从多数类$S_maj$中有效地选择N且满足$\midN\mid=\midS_min\mid$，将N和$\S_min$合并为新的数据集进行训练，新训练集对每个多数类样本$x_i$进行预测若预测对则$S_maj=S_maj-x_i$。依次迭代直到满足某一停止条件，最终的模型是多次迭代模型的组合。所以balance cascade的核心思想是：
* 使用之前已形成的集成分类器来为下一次训练选择多类样本
* 然后再进行欠抽样


##### 基于算法的处理方式

前面讲到对数据集做处理，解决不平衡数据集的问题，我个人认为这不是一种好的方案，特别是在实时数据处理的情景下。因此目前还有一种基于算法处理的方式，使用算法处理不平衡数据主要是基于代价敏感学习，而价敏感学习方法的核心要素是代价矩阵。我们注意到在实际的应用中不同类型的误分类情况导致的代价是不一样的，例如在医疗中，“将病人误疹为健康人”和“将健康人误疹为病人”的代价不同；在信用卡盗用检测中，“将盗用误认为正常使用”与“将正常使用识破认为盗用”的代价也不相同，因此我们定义代价矩阵如下图所示。标记$C_ij$为将类别j误分类为类别i的代价，显然$C_00=C_11=0$，$C_01,C_10$为两种不同的误分类代价，当$C_01＝C_10$的时候，是代价不敏感。


![](http://upload-images.jianshu.io/upload_images/50828-7e3be9c5ffefa292.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

基于以上代价矩阵的分析，代价敏感学习方法主要有以下三种实现方式，分别是：

1. 从学习模型出发，着眼于对某一具体学习方法的改造，使之能适应不平衡数据下的学习，研究者们针对不同的学习模型如感知机，支持向量机，决策树，神经网络等分别提出了其代价敏感的版本。以代价敏感的决策树为例，可从三个方面对其进行改进以适应不平衡数据的学习，这三个方面分别是决策阈值的选择方面、分裂标准的选择方面、剪枝方面，这三个方面中都可以将代价矩阵引入。

2. 从贝叶斯风险理论出发，把代价敏感学习看成是分类结果的一种后处理，按照传统方法学习到一个模型，以实现损失最小为目标对结果进行调整，优化公式如下所示。此方法的优点在于它可以不依赖所用具体的分类器，但是缺点也很明显它要求分类器输出值为概率。
![](http://upload-images.jianshu.io/upload_images/50828-cd2dfca4f0e2c807.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

3. 从预处理的角度出发，将代价用于权重的调整，使得分类器满足代价敏感的特性。
![](http://www.analyticsvidhya.com/wp-content/uploads/2015/11/bigd.png)
上图是一个基于权重调节的方式，从图中可以看到，在Box1的时候，通过分类器D1，将左边的加号识别出了，但是右边的三个蓝色的加号并没有被正常的识别，因此对其进行加权。在进行第二轮也就是Box2中，D2分类器未识别出的三个红色减号，也对其加权，带圆框的表示识别错误，经过n此迭代之后，最终在Box4中对多个结果进行合并，得到正确的结果。

##### 不平衡数据处理的评价方法

通过不平衡数据处理训练出的模型后，需要去检测模型的准确度，也就是选取模型的评价方法。对于评价模型的算法性能，很多人第一时间反应是正确率，但是对于不平衡数据下的模型，这一类方法并不适用，因为模型直接把数据归类给多数类，就能够达到很高的正确率了，所以对于这一类模型，ROC分析方法更加合适，ROC曲线描述的是混淆矩阵中FPR（FP rate）和TPR两个量之间的相对变化关系，那么何谓混淆矩阵？如下表所示：


| Tables        | positive           | negative           |
| ------------- |:------------------:| ------------------:|
| positive      | TP (true positive) | FP (false positive)|
| negative      | FN (false negative)| TN (true negative) |


* TP——将正类预测为正类数。
* FN——将正类预测为负类数。
* FP——将负类预测为正类数。
* TN——将负类预测为负类数。

以二元分类器为研究对象，上面的混淆矩阵显示了一个分类器可能遇到的所有情况，其中列对应于样本实际的类别，行对应于样本被预测的类别，其中考虑一个二分问题，即将实例分成正类（positive）或负类（negative）。对一个二分问题来说，会出现四种情况。如果一个实例是正类并且也被 预测成正类，即为真正类（True positive）,如果实例是负类被预测成正类，称之为假正类（False positive）。相应地，如果实例是负类被预测成负类，称之为真负类（True negative）,正类被预测成负类则为假负类（false negative），这四个基本指标可以衍生出多个分类器指标，包括常用的评价指标是精确率和召回率，定义如下：

* 精确率：![](http://www.bucry.com/usr/uploads/2016/06/4071485463.png)
* 召回率：![](http://www.bucry.com/usr/uploads/2016/06/23188038.png)
* F值：![](http://www.bucry.com/usr/uploads/2016/06/2085633507.png)

其中F值，是召回率和精确率的均值，如果二元分类器给出的是对正样本的一个分类概率，那么通过设定不同的阈值，可以得到不同的混淆矩阵，而每个混淆矩阵都对应于ROC曲线上的一个点。将这些点描绘出来可以得到一条平滑的曲线，这时，我们可以用曲线所包围的面积，即AUC，来评估该二元分类器的可信度，如下图所示：

![](http://upload-images.jianshu.io/upload_images/50828-c4dfff61e3ad58fa.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

通过上面的曲线图，可以发现，大于这个阀值的，判定为正，小于这个阀值的，判定为负，如果减小这个阀值，肯定能够识别更多的正，但是同时也会增加将负判定为正的情况，ROC曲线就形象的描述了这一行为，因此ROC曲线可以用于评价一个分类器。

##### 参考
http://www.jianshu.com/p/3e8b9f2764c8
http://www.di.unipi.it/~cardillo/AA0304/fabio/boosting.pdf
http://pages.stern.nyu.edu/~fprovost/Papers/skew.PDF
http://scikit-learn.org/stable/auto_examples/ensemble/plot_adaboost_twoclass.html
https://www.jair.org/media/953/live-953-2037-jair.pdf
http://cse.seu.edu.cn/people/xyliu/publication/tsmcb09.pdf
https://www.jair.org/media/953/live-953-2037-jair.pdf
http://www.ibm.com/developerworks/cn/opensource/os-cn-spark-random-forest/
